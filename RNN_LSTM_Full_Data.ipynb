{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy9xLUgwZiMa"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kVLIbWft_e2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e8adf9-d587-441b-b7d2-0108b5d564f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Eix89JZnzM"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(NT,nt)   A - 0\n",
        "#(NT,rp)   B - 1\n",
        "#(NT,rt)   C - 2\n",
        "#(NT,tw)   D - 3\n",
        "\n",
        "#(RP,nt)   E - 4\n",
        "#(RP,rp)   F - 5\n",
        "#(RP,rt)   G - 6\n",
        "#(RP,tw)   H - 7\n",
        "   \n",
        "#(RT,nt)   I - 8\n",
        "#(RT,rp)   J - 9\n",
        "#(RT,rt)   K - 10\n",
        "#(RT,tw)   L - 11\n",
        "\n",
        "def reconstruct_traj(row):\n",
        "    f_i=row\n",
        "    f_i=f_i[1:]\n",
        "    f_i = f_i[:-1]\n",
        "    s=str(f_i)\n",
        "    s=s.replace(\" \", \"\")\n",
        "    x = s.split(\"[\")\n",
        "\n",
        "    t=[]\n",
        "    for i in range(0,len(x)):\n",
        "        r=x[i].replace(\"]\", \"\").split(\",\")\n",
        "        if len(r) >=2:\n",
        "            t.append([r[0],r[1]])\n",
        "    \n",
        "    return t\n",
        "\n",
        "def remove_action(traj):   ##keep only the S_A pair\n",
        "    seq=[]\n",
        "    #print(traj)\n",
        "    for i in range(len(traj)):\n",
        "        seq.append(int(traj[i][0]))\n",
        "    return seq\n",
        "\n",
        "users_traj = pd.read_csv(\"/content/drive/MyDrive/Trajectories+code/users_all_trajectories.csv\") \n",
        "trolls_traj=pd.read_csv(\"/content/drive/MyDrive/Trajectories+code/trolls_all_trajectories.csv\")\n",
        "\n",
        "users_traj['state_sequence'] = users_traj.apply(lambda row : reconstruct_traj(row['state_sequence']), axis = 1)\n",
        "trolls_traj['state_sequence'] = trolls_traj.apply(lambda row : reconstruct_traj(row['state_sequence']), axis = 1)\n",
        "\n",
        "users_traj['sequence_numbers'] = users_traj.apply(lambda row : remove_action(row['state_sequence']), axis = 1)\n",
        "trolls_traj['sequence_numbers'] = trolls_traj.apply(lambda row : remove_action(row['state_sequence']), axis = 1)\n",
        "\n",
        "users_traj['label'] = 0\n",
        "trolls_traj['label']= 1\n",
        "\n",
        "frames = [users_traj, trolls_traj]\n",
        "data = pd.concat(frames)\n",
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "mX2Qm2r7TCpe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQC28RbqPebz",
        "outputId": "eef216e5-2577-4c2f-c0e5-46ffdf089dc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2322"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train - Test Split over all users/trolls\n",
        "data_train, data_test = train_test_split(data, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "74S3DldcPbps"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_test[data_test['label'] == 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHdfp082znMg",
        "outputId": "94f01fe9-9251-4447-ffdd-afa5831f7139"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qGxXwm2ZL_Z"
      },
      "source": [
        "### Trajectory Formation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TdXPiCdEe_Pd"
      },
      "outputs": [],
      "source": [
        "#preparing the splitted sequences of trainig users/trolls\n",
        "users = data_train[data_train['label']==0].reset_index(drop=True)\n",
        "trolls = data_train[data_train['label']==1].reset_index(drop=True)\n",
        "max_length = 200 #trajectory Length: L. LSTM input\n",
        "new_data = pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "count=0\n",
        "#users\n",
        "#iterating over users from training set\n",
        "for i in range(len(users)):\n",
        "  user = users.loc[i]\n",
        "  traj = users.loc[i]['sequence_numbers']\n",
        "  l = len(traj)\n",
        "\n",
        "  if l <= max_length: #if trajectory length less then max_lenght add it as it is\n",
        "    res=traj\n",
        "    new_data.loc[count]=[res,0] # label 0 for users\n",
        "    count=count+1\n",
        "\n",
        "  else:  #else split it into records\n",
        "    res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "    for j in range(len(res)):\n",
        "      new_data.loc[count]=[res[j].tolist(),0] # label 0 for users\n",
        "      count=count+1\n",
        "      \n",
        "new_data_trolls=pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "\n",
        "count=0\n",
        "#trolls\n",
        "#iterating over trolls from training set\n",
        "for i in range(len(trolls)):\n",
        "  troll=trolls.loc[i]\n",
        "  traj = trolls.loc[i]['sequence_numbers']\n",
        "  l = len(traj)\n",
        "\n",
        "  if l <= max_length:  #if trajectory length less then max_lenght add it as it is\n",
        "    res=traj\n",
        "    new_data_trolls.loc[count]=[res,1]\n",
        "    count=count+1\n",
        "\n",
        "  else: #else split it into records\n",
        "    res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "    for j in range(len(res)):\n",
        "      new_data_trolls.loc[count]=[res[j].tolist(),1]\n",
        "      count=count+1\n",
        "\n",
        "#all_data is the dataframe that contains the extracted sequences of users and trolls from train set\n",
        "frames = [new_data, new_data_trolls]\n",
        "all_train_data = pd.concat(frames)\n",
        "all_train_data = all_train_data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F05PgNHTxrCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5acd8b-370d-4908-b148-765cd43a03f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " After Splitting Training Set  --> Users : 21663 Trolls : 12796\n"
          ]
        }
      ],
      "source": [
        "print (\" After Splitting Training Set  --> Users : \" + str(len(new_data)) +\" Trolls : \" +str(len(new_data_trolls)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same for test set extracting the trajectories\n",
        "#preparing the splitted sequences\n",
        "users = data_test[data_test['label']==0].reset_index(drop=True)\n",
        "trolls = data_test[data_test['label']==1].reset_index(drop=True)\n",
        "max_length = 200 #trajectory Length: L. LSTM input\n",
        "new_data = pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "count=0\n",
        "#users\n",
        "for i in range(len(users)):\n",
        "  user = users.loc[i]\n",
        "  traj = users.loc[i]['sequence_numbers']\n",
        "  l = len(traj)\n",
        "\n",
        "  if l <= max_length: #if trajectory length less then max_lenght add it as it is\n",
        "    res=traj\n",
        "    new_data.loc[count]=[res,0]\n",
        "    count=count+1\n",
        "\n",
        "  else:  #else split it into records\n",
        "    res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "    for j in range(len(res)):\n",
        "      new_data.loc[count]=[res[j].tolist(),0]\n",
        "      count=count+1\n",
        "      \n",
        "new_data_trolls=pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "\n",
        "count=0\n",
        "#trolls\n",
        "#iterating over trolls\n",
        "for i in range(len(trolls)):\n",
        "  troll=trolls.loc[i]\n",
        "  traj = trolls.loc[i]['sequence_numbers']\n",
        "  l = len(traj)\n",
        "\n",
        "  if l <= max_length:  #if trajectory length less then max_lenght add it as it is\n",
        "    res=traj\n",
        "    new_data_trolls.loc[count]=[res,1]\n",
        "    count=count+1\n",
        "\n",
        "  else: #else split it into records\n",
        "    res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "    for j in range(len(res)):\n",
        "      new_data_trolls.loc[count]=[res[j].tolist(),1]\n",
        "      count=count+1\n",
        "\n",
        "#all_data is the dataframe that contains the extracted sequences\n",
        "frames = [new_data, new_data_trolls]\n",
        "all_test_data = pd.concat(frames)\n",
        "all_test_data = all_test_data.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "prMVEiAaPueF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\" After Splitting Test Set--> Users : \" + str(len(new_data)) +\" Trolls : \" +str(len(new_data_trolls)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieb2-BrXQGy7",
        "outputId": "9aadaae5-228e-498e-b528-3254b8f0ef94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " After Splitting Test Set--> Users : 3636 Trolls : 3434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trajectory Classification\n",
        "Training with 85% train and 15% test"
      ],
      "metadata": {
        "id": "Ap2AOnT5aEIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U9F6Z-jv6P3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419609fc-9f67-4fcc-a5fd-792c1f8fa8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29290, 200) (29290,)\n",
            "(5169, 200) (5169,)\n",
            "(29290, 200, 1) (29290,)\n",
            "(5169, 200, 1) (5169,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "293/293 [==============================] - 25s 47ms/step - loss: 0.2253 - acc: 0.9245 - auc: 0.9574 - false_negatives: 812.0000 - false_positives: 1400.0000 - true_negatives: 17050.0000 - true_positives: 10028.0000 - precision: 0.8775 - recall: 0.9251 - val_loss: 0.1943 - val_acc: 0.9334 - val_auc: 0.9707 - val_false_negatives: 131.0000 - val_false_positives: 213.0000 - val_true_negatives: 3000.0000 - val_true_positives: 1825.0000 - val_precision: 0.8955 - val_recall: 0.9330\n",
            "Epoch 2/100\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2062 - acc: 0.9250 - auc: 0.9659 - false_negatives: 995.0000 - false_positives: 1201.0000 - true_negatives: 17249.0000 - true_positives: 9845.0000 - precision: 0.8913 - recall: 0.9082 - val_loss: 0.2166 - val_acc: 0.9317 - val_auc: 0.9477 - val_false_negatives: 57.0000 - val_false_positives: 296.0000 - val_true_negatives: 2917.0000 - val_true_positives: 1899.0000 - val_precision: 0.8651 - val_recall: 0.9709\n",
            "Epoch 3/100\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2478 - acc: 0.9220 - auc: 0.9494 - false_negatives: 1111.0000 - false_positives: 1173.0000 - true_negatives: 17277.0000 - true_positives: 9729.0000 - precision: 0.8924 - recall: 0.8975 - val_loss: 0.2267 - val_acc: 0.9352 - val_auc: 0.9792 - val_false_negatives: 192.0000 - val_false_positives: 143.0000 - val_true_negatives: 3070.0000 - val_true_positives: 1764.0000 - val_precision: 0.9250 - val_recall: 0.9018\n",
            "Epoch 4/100\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2218 - acc: 0.9279 - auc: 0.9584 - false_negatives: 858.0000 - false_positives: 1254.0000 - true_negatives: 17196.0000 - true_positives: 9982.0000 - precision: 0.8884 - recall: 0.9208 - val_loss: 0.1786 - val_acc: 0.9327 - val_auc: 0.9815 - val_false_negatives: 113.0000 - val_false_positives: 235.0000 - val_true_negatives: 2978.0000 - val_true_positives: 1843.0000 - val_precision: 0.8869 - val_recall: 0.9422\n",
            "Epoch 5/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.2130 - acc: 0.9280 - auc: 0.9603 - false_negatives: 760.0000 - false_positives: 1348.0000 - true_negatives: 17102.0000 - true_positives: 10080.0000 - precision: 0.8820 - recall: 0.9299 - val_loss: 0.1868 - val_acc: 0.9350 - val_auc: 0.9704 - val_false_negatives: 148.0000 - val_false_positives: 188.0000 - val_true_negatives: 3025.0000 - val_true_positives: 1808.0000 - val_precision: 0.9058 - val_recall: 0.9243\n",
            "Epoch 6/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.2101 - acc: 0.9271 - auc: 0.9635 - false_negatives: 829.0000 - false_positives: 1305.0000 - true_negatives: 17145.0000 - true_positives: 10011.0000 - precision: 0.8847 - recall: 0.9235 - val_loss: 0.1920 - val_acc: 0.9340 - val_auc: 0.9780 - val_false_negatives: 101.0000 - val_false_positives: 240.0000 - val_true_negatives: 2973.0000 - val_true_positives: 1855.0000 - val_precision: 0.8854 - val_recall: 0.9484\n",
            "Epoch 7/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.1948 - acc: 0.9295 - auc: 0.9702 - false_negatives: 978.0000 - false_positives: 1086.0000 - true_negatives: 17364.0000 - true_positives: 9862.0000 - precision: 0.9008 - recall: 0.9098 - val_loss: 0.1749 - val_acc: 0.9358 - val_auc: 0.9826 - val_false_negatives: 175.0000 - val_false_positives: 157.0000 - val_true_negatives: 3056.0000 - val_true_positives: 1781.0000 - val_precision: 0.9190 - val_recall: 0.9105\n",
            "Epoch 8/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2107 - acc: 0.9214 - auc: 0.9677 - false_negatives: 1133.0000 - false_positives: 1170.0000 - true_negatives: 17280.0000 - true_positives: 9707.0000 - precision: 0.8924 - recall: 0.8955 - val_loss: 0.2345 - val_acc: 0.9193 - val_auc: 0.9611 - val_false_negatives: 120.0000 - val_false_positives: 297.0000 - val_true_negatives: 2916.0000 - val_true_positives: 1836.0000 - val_precision: 0.8608 - val_recall: 0.9387\n",
            "Epoch 9/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2375 - acc: 0.9173 - auc: 0.9560 - false_negatives: 1219.0000 - false_positives: 1203.0000 - true_negatives: 17247.0000 - true_positives: 9621.0000 - precision: 0.8889 - recall: 0.8875 - val_loss: 0.2017 - val_acc: 0.9315 - val_auc: 0.9660 - val_false_negatives: 214.0000 - val_false_positives: 140.0000 - val_true_negatives: 3073.0000 - val_true_positives: 1742.0000 - val_precision: 0.9256 - val_recall: 0.8906\n",
            "Epoch 10/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2489 - acc: 0.9158 - auc: 0.9498 - false_negatives: 1120.0000 - false_positives: 1345.0000 - true_negatives: 17105.0000 - true_positives: 9720.0000 - precision: 0.8784 - recall: 0.8967 - val_loss: 0.2182 - val_acc: 0.9240 - val_auc: 0.9566 - val_false_negatives: 78.0000 - val_false_positives: 315.0000 - val_true_negatives: 2898.0000 - val_true_positives: 1878.0000 - val_precision: 0.8564 - val_recall: 0.9601\n",
            "Epoch 11/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.2154 - acc: 0.9261 - auc: 0.9587 - false_negatives: 661.0000 - false_positives: 1504.0000 - true_negatives: 16946.0000 - true_positives: 10179.0000 - precision: 0.8713 - recall: 0.9390 - val_loss: 0.1770 - val_acc: 0.9367 - val_auc: 0.9701 - val_false_negatives: 173.0000 - val_false_positives: 154.0000 - val_true_negatives: 3059.0000 - val_true_positives: 1783.0000 - val_precision: 0.9205 - val_recall: 0.9116\n",
            "Epoch 12/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.1959 - acc: 0.9289 - auc: 0.9677 - false_negatives: 807.0000 - false_positives: 1276.0000 - true_negatives: 17174.0000 - true_positives: 10033.0000 - precision: 0.8872 - recall: 0.9256 - val_loss: 0.1654 - val_acc: 0.9365 - val_auc: 0.9774 - val_false_negatives: 145.0000 - val_false_positives: 183.0000 - val_true_negatives: 3030.0000 - val_true_positives: 1811.0000 - val_precision: 0.9082 - val_recall: 0.9259\n",
            "Epoch 13/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.1820 - acc: 0.9284 - auc: 0.9766 - false_negatives: 923.0000 - false_positives: 1173.0000 - true_negatives: 17277.0000 - true_positives: 9917.0000 - precision: 0.8942 - recall: 0.9149 - val_loss: 0.1540 - val_acc: 0.9391 - val_auc: 0.9868 - val_false_negatives: 198.0000 - val_false_positives: 117.0000 - val_true_negatives: 3096.0000 - val_true_positives: 1758.0000 - val_precision: 0.9376 - val_recall: 0.8988\n",
            "Epoch 14/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.1727 - acc: 0.9306 - auc: 0.9789 - false_negatives: 956.0000 - false_positives: 1076.0000 - true_negatives: 17374.0000 - true_positives: 9884.0000 - precision: 0.9018 - recall: 0.9118 - val_loss: 0.1526 - val_acc: 0.9375 - val_auc: 0.9870 - val_false_negatives: 223.0000 - val_false_positives: 100.0000 - val_true_negatives: 3113.0000 - val_true_positives: 1733.0000 - val_precision: 0.9454 - val_recall: 0.8860\n",
            "Epoch 15/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.1572 - acc: 0.9326 - auc: 0.9825 - false_negatives: 1050.0000 - false_positives: 925.0000 - true_negatives: 17525.0000 - true_positives: 9790.0000 - precision: 0.9137 - recall: 0.9031 - val_loss: 0.1410 - val_acc: 0.9367 - val_auc: 0.9874 - val_false_negatives: 162.0000 - val_false_positives: 165.0000 - val_true_negatives: 3048.0000 - val_true_positives: 1794.0000 - val_precision: 0.9158 - val_recall: 0.9172\n",
            "Epoch 16/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.1532 - acc: 0.9346 - auc: 0.9836 - false_negatives: 1120.0000 - false_positives: 795.0000 - true_negatives: 17655.0000 - true_positives: 9720.0000 - precision: 0.9244 - recall: 0.8967 - val_loss: 0.1350 - val_acc: 0.9369 - val_auc: 0.9878 - val_false_negatives: 79.0000 - val_false_positives: 247.0000 - val_true_negatives: 2966.0000 - val_true_positives: 1877.0000 - val_precision: 0.8837 - val_recall: 0.9596\n",
            "Epoch 17/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.1355 - acc: 0.9416 - auc: 0.9863 - false_negatives: 1176.0000 - false_positives: 535.0000 - true_negatives: 17915.0000 - true_positives: 9664.0000 - precision: 0.9475 - recall: 0.8915 - val_loss: 0.1132 - val_acc: 0.9524 - val_auc: 0.9918 - val_false_negatives: 205.0000 - val_false_positives: 41.0000 - val_true_negatives: 3172.0000 - val_true_positives: 1751.0000 - val_precision: 0.9771 - val_recall: 0.8952\n",
            "Epoch 18/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.1310 - acc: 0.9451 - auc: 0.9873 - false_negatives: 1199.0000 - false_positives: 410.0000 - true_negatives: 18040.0000 - true_positives: 9641.0000 - precision: 0.9592 - recall: 0.8894 - val_loss: 0.1140 - val_acc: 0.9543 - val_auc: 0.9918 - val_false_negatives: 201.0000 - val_false_positives: 35.0000 - val_true_negatives: 3178.0000 - val_true_positives: 1755.0000 - val_precision: 0.9804 - val_recall: 0.8972\n",
            "Epoch 19/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.1207 - acc: 0.9526 - auc: 0.9882 - false_negatives: 993.0000 - false_positives: 396.0000 - true_negatives: 18054.0000 - true_positives: 9847.0000 - precision: 0.9613 - recall: 0.9084 - val_loss: 0.1091 - val_acc: 0.9592 - val_auc: 0.9916 - val_false_negatives: 171.0000 - val_false_positives: 40.0000 - val_true_negatives: 3173.0000 - val_true_positives: 1785.0000 - val_precision: 0.9781 - val_recall: 0.9126\n",
            "Epoch 20/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.1099 - acc: 0.9594 - auc: 0.9897 - false_negatives: 786.0000 - false_positives: 403.0000 - true_negatives: 18047.0000 - true_positives: 10054.0000 - precision: 0.9615 - recall: 0.9275 - val_loss: 0.0766 - val_acc: 0.9747 - val_auc: 0.9950 - val_false_negatives: 97.0000 - val_false_positives: 34.0000 - val_true_negatives: 3179.0000 - val_true_positives: 1859.0000 - val_precision: 0.9820 - val_recall: 0.9504\n",
            "Epoch 21/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0913 - acc: 0.9682 - auc: 0.9925 - false_negatives: 541.0000 - false_positives: 389.0000 - true_negatives: 18061.0000 - true_positives: 10299.0000 - precision: 0.9636 - recall: 0.9501 - val_loss: 0.0771 - val_acc: 0.9718 - val_auc: 0.9952 - val_false_negatives: 55.0000 - val_false_positives: 91.0000 - val_true_negatives: 3122.0000 - val_true_positives: 1901.0000 - val_precision: 0.9543 - val_recall: 0.9719\n",
            "Epoch 22/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0885 - acc: 0.9704 - auc: 0.9926 - false_negatives: 533.0000 - false_positives: 333.0000 - true_negatives: 18117.0000 - true_positives: 10307.0000 - precision: 0.9687 - recall: 0.9508 - val_loss: 0.0677 - val_acc: 0.9797 - val_auc: 0.9962 - val_false_negatives: 56.0000 - val_false_positives: 49.0000 - val_true_negatives: 3164.0000 - val_true_positives: 1900.0000 - val_precision: 0.9749 - val_recall: 0.9714\n",
            "Epoch 23/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0781 - acc: 0.9747 - auc: 0.9939 - false_negatives: 480.0000 - false_positives: 261.0000 - true_negatives: 18189.0000 - true_positives: 10360.0000 - precision: 0.9754 - recall: 0.9557 - val_loss: 0.0616 - val_acc: 0.9814 - val_auc: 0.9964 - val_false_negatives: 54.0000 - val_false_positives: 42.0000 - val_true_negatives: 3171.0000 - val_true_positives: 1902.0000 - val_precision: 0.9784 - val_recall: 0.9724\n",
            "Epoch 24/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0704 - acc: 0.9774 - auc: 0.9948 - false_negatives: 454.0000 - false_positives: 207.0000 - true_negatives: 18243.0000 - true_positives: 10386.0000 - precision: 0.9805 - recall: 0.9581 - val_loss: 0.0572 - val_acc: 0.9843 - val_auc: 0.9972 - val_false_negatives: 47.0000 - val_false_positives: 34.0000 - val_true_negatives: 3179.0000 - val_true_positives: 1909.0000 - val_precision: 0.9825 - val_recall: 0.9760\n",
            "Epoch 25/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0640 - acc: 0.9797 - auc: 0.9956 - false_negatives: 411.0000 - false_positives: 183.0000 - true_negatives: 18267.0000 - true_positives: 10429.0000 - precision: 0.9828 - recall: 0.9621 - val_loss: 0.0527 - val_acc: 0.9841 - val_auc: 0.9971 - val_false_negatives: 71.0000 - val_false_positives: 11.0000 - val_true_negatives: 3202.0000 - val_true_positives: 1885.0000 - val_precision: 0.9942 - val_recall: 0.9637\n",
            "Epoch 26/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0631 - acc: 0.9797 - auc: 0.9957 - false_negatives: 422.0000 - false_positives: 174.0000 - true_negatives: 18276.0000 - true_positives: 10418.0000 - precision: 0.9836 - recall: 0.9611 - val_loss: 0.0508 - val_acc: 0.9855 - val_auc: 0.9971 - val_false_negatives: 44.0000 - val_false_positives: 31.0000 - val_true_negatives: 3182.0000 - val_true_positives: 1912.0000 - val_precision: 0.9840 - val_recall: 0.9775\n",
            "Epoch 27/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0601 - acc: 0.9812 - auc: 0.9962 - false_negatives: 375.0000 - false_positives: 175.0000 - true_negatives: 18275.0000 - true_positives: 10465.0000 - precision: 0.9836 - recall: 0.9654 - val_loss: 0.0496 - val_acc: 0.9845 - val_auc: 0.9970 - val_false_negatives: 54.0000 - val_false_positives: 26.0000 - val_true_negatives: 3187.0000 - val_true_positives: 1902.0000 - val_precision: 0.9865 - val_recall: 0.9724\n",
            "Epoch 28/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0568 - acc: 0.9814 - auc: 0.9967 - false_negatives: 379.0000 - false_positives: 166.0000 - true_negatives: 18284.0000 - true_positives: 10461.0000 - precision: 0.9844 - recall: 0.9650 - val_loss: 0.0441 - val_acc: 0.9868 - val_auc: 0.9970 - val_false_negatives: 48.0000 - val_false_positives: 20.0000 - val_true_negatives: 3193.0000 - val_true_positives: 1908.0000 - val_precision: 0.9896 - val_recall: 0.9755\n",
            "Epoch 29/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0536 - acc: 0.9830 - auc: 0.9967 - false_negatives: 336.0000 - false_positives: 162.0000 - true_negatives: 18288.0000 - true_positives: 10504.0000 - precision: 0.9848 - recall: 0.9690 - val_loss: 0.0478 - val_acc: 0.9876 - val_auc: 0.9970 - val_false_negatives: 40.0000 - val_false_positives: 24.0000 - val_true_negatives: 3189.0000 - val_true_positives: 1916.0000 - val_precision: 0.9876 - val_recall: 0.9796\n",
            "Epoch 30/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0563 - acc: 0.9816 - auc: 0.9965 - false_negatives: 369.0000 - false_positives: 169.0000 - true_negatives: 18281.0000 - true_positives: 10471.0000 - precision: 0.9841 - recall: 0.9660 - val_loss: 0.0477 - val_acc: 0.9832 - val_auc: 0.9979 - val_false_negatives: 51.0000 - val_false_positives: 36.0000 - val_true_negatives: 3177.0000 - val_true_positives: 1905.0000 - val_precision: 0.9815 - val_recall: 0.9739\n",
            "Epoch 31/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0525 - acc: 0.9834 - auc: 0.9967 - false_negatives: 339.0000 - false_positives: 148.0000 - true_negatives: 18302.0000 - true_positives: 10501.0000 - precision: 0.9861 - recall: 0.9687 - val_loss: 0.0437 - val_acc: 0.9867 - val_auc: 0.9976 - val_false_negatives: 33.0000 - val_false_positives: 36.0000 - val_true_negatives: 3177.0000 - val_true_positives: 1923.0000 - val_precision: 0.9816 - val_recall: 0.9831\n",
            "Epoch 32/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0514 - acc: 0.9831 - auc: 0.9970 - false_negatives: 330.0000 - false_positives: 164.0000 - true_negatives: 18286.0000 - true_positives: 10510.0000 - precision: 0.9846 - recall: 0.9696 - val_loss: 0.0417 - val_acc: 0.9880 - val_auc: 0.9977 - val_false_negatives: 36.0000 - val_false_positives: 26.0000 - val_true_negatives: 3187.0000 - val_true_positives: 1920.0000 - val_precision: 0.9866 - val_recall: 0.9816\n",
            "Epoch 33/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0491 - acc: 0.9847 - auc: 0.9973 - false_negatives: 295.0000 - false_positives: 154.0000 - true_negatives: 18296.0000 - true_positives: 10545.0000 - precision: 0.9856 - recall: 0.9728 - val_loss: 0.0408 - val_acc: 0.9876 - val_auc: 0.9976 - val_false_negatives: 45.0000 - val_false_positives: 19.0000 - val_true_negatives: 3194.0000 - val_true_positives: 1911.0000 - val_precision: 0.9902 - val_recall: 0.9770\n",
            "Epoch 34/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0480 - acc: 0.9838 - auc: 0.9974 - false_negatives: 286.0000 - false_positives: 188.0000 - true_negatives: 18262.0000 - true_positives: 10554.0000 - precision: 0.9825 - recall: 0.9736 - val_loss: 0.0427 - val_acc: 0.9868 - val_auc: 0.9972 - val_false_negatives: 33.0000 - val_false_positives: 35.0000 - val_true_negatives: 3178.0000 - val_true_positives: 1923.0000 - val_precision: 0.9821 - val_recall: 0.9831\n",
            "Epoch 35/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0484 - acc: 0.9840 - auc: 0.9971 - false_negatives: 283.0000 - false_positives: 185.0000 - true_negatives: 18265.0000 - true_positives: 10557.0000 - precision: 0.9828 - recall: 0.9739 - val_loss: 0.0408 - val_acc: 0.9878 - val_auc: 0.9981 - val_false_negatives: 31.0000 - val_false_positives: 32.0000 - val_true_negatives: 3181.0000 - val_true_positives: 1925.0000 - val_precision: 0.9836 - val_recall: 0.9842\n",
            "Epoch 36/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0467 - acc: 0.9842 - auc: 0.9977 - false_negatives: 289.0000 - false_positives: 173.0000 - true_negatives: 18277.0000 - true_positives: 10551.0000 - precision: 0.9839 - recall: 0.9733 - val_loss: 0.0420 - val_acc: 0.9874 - val_auc: 0.9971 - val_false_negatives: 40.0000 - val_false_positives: 25.0000 - val_true_negatives: 3188.0000 - val_true_positives: 1916.0000 - val_precision: 0.9871 - val_recall: 0.9796\n",
            "Epoch 37/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0464 - acc: 0.9836 - auc: 0.9979 - false_negatives: 285.0000 - false_positives: 196.0000 - true_negatives: 18254.0000 - true_positives: 10555.0000 - precision: 0.9818 - recall: 0.9737 - val_loss: 0.0393 - val_acc: 0.9880 - val_auc: 0.9972 - val_false_negatives: 36.0000 - val_false_positives: 26.0000 - val_true_negatives: 3187.0000 - val_true_positives: 1920.0000 - val_precision: 0.9866 - val_recall: 0.9816\n",
            "Epoch 38/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0453 - acc: 0.9851 - auc: 0.9977 - false_negatives: 277.0000 - false_positives: 158.0000 - true_negatives: 18292.0000 - true_positives: 10563.0000 - precision: 0.9853 - recall: 0.9744 - val_loss: 0.0393 - val_acc: 0.9882 - val_auc: 0.9977 - val_false_negatives: 28.0000 - val_false_positives: 33.0000 - val_true_negatives: 3180.0000 - val_true_positives: 1928.0000 - val_precision: 0.9832 - val_recall: 0.9857\n",
            "Epoch 39/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0422 - acc: 0.9851 - auc: 0.9981 - false_negatives: 257.0000 - false_positives: 180.0000 - true_negatives: 18270.0000 - true_positives: 10583.0000 - precision: 0.9833 - recall: 0.9763 - val_loss: 0.0411 - val_acc: 0.9867 - val_auc: 0.9980 - val_false_negatives: 30.0000 - val_false_positives: 39.0000 - val_true_negatives: 3174.0000 - val_true_positives: 1926.0000 - val_precision: 0.9802 - val_recall: 0.9847\n",
            "Epoch 40/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0432 - acc: 0.9850 - auc: 0.9982 - false_negatives: 251.0000 - false_positives: 187.0000 - true_negatives: 18263.0000 - true_positives: 10589.0000 - precision: 0.9826 - recall: 0.9768 - val_loss: 0.0411 - val_acc: 0.9880 - val_auc: 0.9975 - val_false_negatives: 34.0000 - val_false_positives: 28.0000 - val_true_negatives: 3185.0000 - val_true_positives: 1922.0000 - val_precision: 0.9856 - val_recall: 0.9826\n",
            "Epoch 41/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0448 - acc: 0.9853 - auc: 0.9978 - false_negatives: 263.0000 - false_positives: 167.0000 - true_negatives: 18283.0000 - true_positives: 10577.0000 - precision: 0.9845 - recall: 0.9757 - val_loss: 0.0377 - val_acc: 0.9894 - val_auc: 0.9974 - val_false_negatives: 33.0000 - val_false_positives: 22.0000 - val_true_negatives: 3191.0000 - val_true_positives: 1923.0000 - val_precision: 0.9887 - val_recall: 0.9831\n",
            "Epoch 42/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0417 - acc: 0.9849 - auc: 0.9983 - false_negatives: 268.0000 - false_positives: 173.0000 - true_negatives: 18277.0000 - true_positives: 10572.0000 - precision: 0.9839 - recall: 0.9753 - val_loss: 0.0398 - val_acc: 0.9880 - val_auc: 0.9972 - val_false_negatives: 37.0000 - val_false_positives: 25.0000 - val_true_negatives: 3188.0000 - val_true_positives: 1919.0000 - val_precision: 0.9871 - val_recall: 0.9811\n",
            "Epoch 43/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0404 - acc: 0.9860 - auc: 0.9982 - false_negatives: 235.0000 - false_positives: 174.0000 - true_negatives: 18276.0000 - true_positives: 10605.0000 - precision: 0.9839 - recall: 0.9783 - val_loss: 0.0386 - val_acc: 0.9886 - val_auc: 0.9964 - val_false_negatives: 43.0000 - val_false_positives: 16.0000 - val_true_negatives: 3197.0000 - val_true_positives: 1913.0000 - val_precision: 0.9917 - val_recall: 0.9780\n",
            "Epoch 44/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0426 - acc: 0.9844 - auc: 0.9980 - false_negatives: 268.0000 - false_positives: 189.0000 - true_negatives: 18261.0000 - true_positives: 10572.0000 - precision: 0.9824 - recall: 0.9753 - val_loss: 0.0384 - val_acc: 0.9868 - val_auc: 0.9978 - val_false_negatives: 39.0000 - val_false_positives: 29.0000 - val_true_negatives: 3184.0000 - val_true_positives: 1917.0000 - val_precision: 0.9851 - val_recall: 0.9801\n",
            "Epoch 45/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0399 - acc: 0.9862 - auc: 0.9983 - false_negatives: 227.0000 - false_positives: 177.0000 - true_negatives: 18273.0000 - true_positives: 10613.0000 - precision: 0.9836 - recall: 0.9791 - val_loss: 0.0397 - val_acc: 0.9884 - val_auc: 0.9984 - val_false_negatives: 33.0000 - val_false_positives: 27.0000 - val_true_negatives: 3186.0000 - val_true_positives: 1923.0000 - val_precision: 0.9862 - val_recall: 0.9831\n",
            "Epoch 46/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0408 - acc: 0.9855 - auc: 0.9983 - false_negatives: 241.0000 - false_positives: 185.0000 - true_negatives: 18265.0000 - true_positives: 10599.0000 - precision: 0.9828 - recall: 0.9778 - val_loss: 0.0354 - val_acc: 0.9884 - val_auc: 0.9980 - val_false_negatives: 31.0000 - val_false_positives: 29.0000 - val_true_negatives: 3184.0000 - val_true_positives: 1925.0000 - val_precision: 0.9852 - val_recall: 0.9842\n",
            "Epoch 47/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0370 - acc: 0.9875 - auc: 0.9985 - false_negatives: 196.0000 - false_positives: 170.0000 - true_negatives: 18280.0000 - true_positives: 10644.0000 - precision: 0.9843 - recall: 0.9819 - val_loss: 0.0359 - val_acc: 0.9901 - val_auc: 0.9972 - val_false_negatives: 26.0000 - val_false_positives: 25.0000 - val_true_negatives: 3188.0000 - val_true_positives: 1930.0000 - val_precision: 0.9872 - val_recall: 0.9867\n",
            "Epoch 48/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0369 - acc: 0.9875 - auc: 0.9986 - false_negatives: 196.0000 - false_positives: 170.0000 - true_negatives: 18280.0000 - true_positives: 10644.0000 - precision: 0.9843 - recall: 0.9819 - val_loss: 0.0411 - val_acc: 0.9865 - val_auc: 0.9981 - val_false_negatives: 25.0000 - val_false_positives: 45.0000 - val_true_negatives: 3168.0000 - val_true_positives: 1931.0000 - val_precision: 0.9772 - val_recall: 0.9872\n",
            "Epoch 49/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0384 - acc: 0.9865 - auc: 0.9983 - false_negatives: 221.0000 - false_positives: 173.0000 - true_negatives: 18277.0000 - true_positives: 10619.0000 - precision: 0.9840 - recall: 0.9796 - val_loss: 0.0375 - val_acc: 0.9892 - val_auc: 0.9980 - val_false_negatives: 25.0000 - val_false_positives: 31.0000 - val_true_negatives: 3182.0000 - val_true_positives: 1931.0000 - val_precision: 0.9842 - val_recall: 0.9872\n",
            "Epoch 50/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0374 - acc: 0.9873 - auc: 0.9985 - false_negatives: 193.0000 - false_positives: 179.0000 - true_negatives: 18271.0000 - true_positives: 10647.0000 - precision: 0.9835 - recall: 0.9822 - val_loss: 0.0378 - val_acc: 0.9890 - val_auc: 0.9979 - val_false_negatives: 28.0000 - val_false_positives: 29.0000 - val_true_negatives: 3184.0000 - val_true_positives: 1928.0000 - val_precision: 0.9852 - val_recall: 0.9857\n",
            "Epoch 51/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0374 - acc: 0.9875 - auc: 0.9983 - false_negatives: 209.0000 - false_positives: 158.0000 - true_negatives: 18292.0000 - true_positives: 10631.0000 - precision: 0.9854 - recall: 0.9807 - val_loss: 0.0368 - val_acc: 0.9886 - val_auc: 0.9979 - val_false_negatives: 25.0000 - val_false_positives: 34.0000 - val_true_negatives: 3179.0000 - val_true_positives: 1931.0000 - val_precision: 0.9827 - val_recall: 0.9872\n",
            "Epoch 52/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0410 - acc: 0.9867 - auc: 0.9979 - false_negatives: 228.0000 - false_positives: 163.0000 - true_negatives: 18287.0000 - true_positives: 10612.0000 - precision: 0.9849 - recall: 0.9790 - val_loss: 0.0378 - val_acc: 0.9888 - val_auc: 0.9980 - val_false_negatives: 34.0000 - val_false_positives: 24.0000 - val_true_negatives: 3189.0000 - val_true_positives: 1922.0000 - val_precision: 0.9877 - val_recall: 0.9826\n",
            "Epoch 53/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0385 - acc: 0.9867 - auc: 0.9984 - false_negatives: 247.0000 - false_positives: 144.0000 - true_negatives: 18306.0000 - true_positives: 10593.0000 - precision: 0.9866 - recall: 0.9772 - val_loss: 0.0370 - val_acc: 0.9886 - val_auc: 0.9971 - val_false_negatives: 39.0000 - val_false_positives: 20.0000 - val_true_negatives: 3193.0000 - val_true_positives: 1917.0000 - val_precision: 0.9897 - val_recall: 0.9801\n",
            "Epoch 54/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0369 - acc: 0.9869 - auc: 0.9985 - false_negatives: 225.0000 - false_positives: 160.0000 - true_negatives: 18290.0000 - true_positives: 10615.0000 - precision: 0.9852 - recall: 0.9792 - val_loss: 0.0361 - val_acc: 0.9884 - val_auc: 0.9973 - val_false_negatives: 32.0000 - val_false_positives: 28.0000 - val_true_negatives: 3185.0000 - val_true_positives: 1924.0000 - val_precision: 0.9857 - val_recall: 0.9836\n",
            "Epoch 55/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0344 - acc: 0.9881 - auc: 0.9987 - false_negatives: 179.0000 - false_positives: 170.0000 - true_negatives: 18280.0000 - true_positives: 10661.0000 - precision: 0.9843 - recall: 0.9835 - val_loss: 0.0331 - val_acc: 0.9892 - val_auc: 0.9987 - val_false_negatives: 31.0000 - val_false_positives: 25.0000 - val_true_negatives: 3188.0000 - val_true_positives: 1925.0000 - val_precision: 0.9872 - val_recall: 0.9842\n",
            "Epoch 56/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0334 - acc: 0.9890 - auc: 0.9988 - false_negatives: 183.0000 - false_positives: 138.0000 - true_negatives: 18312.0000 - true_positives: 10657.0000 - precision: 0.9872 - recall: 0.9831 - val_loss: 0.0385 - val_acc: 0.9870 - val_auc: 0.9984 - val_false_negatives: 21.0000 - val_false_positives: 46.0000 - val_true_negatives: 3167.0000 - val_true_positives: 1935.0000 - val_precision: 0.9768 - val_recall: 0.9893\n",
            "Epoch 57/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0327 - acc: 0.9892 - auc: 0.9987 - false_negatives: 178.0000 - false_positives: 138.0000 - true_negatives: 18312.0000 - true_positives: 10662.0000 - precision: 0.9872 - recall: 0.9836 - val_loss: 0.0425 - val_acc: 0.9857 - val_auc: 0.9969 - val_false_negatives: 31.0000 - val_false_positives: 43.0000 - val_true_negatives: 3170.0000 - val_true_positives: 1925.0000 - val_precision: 0.9782 - val_recall: 0.9842\n",
            "Epoch 58/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0351 - acc: 0.9877 - auc: 0.9987 - false_negatives: 191.0000 - false_positives: 170.0000 - true_negatives: 18280.0000 - true_positives: 10649.0000 - precision: 0.9843 - recall: 0.9824 - val_loss: 0.0409 - val_acc: 0.9882 - val_auc: 0.9975 - val_false_negatives: 24.0000 - val_false_positives: 37.0000 - val_true_negatives: 3176.0000 - val_true_positives: 1932.0000 - val_precision: 0.9812 - val_recall: 0.9877\n",
            "Epoch 59/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0350 - acc: 0.9882 - auc: 0.9986 - false_negatives: 171.0000 - false_positives: 174.0000 - true_negatives: 18276.0000 - true_positives: 10669.0000 - precision: 0.9840 - recall: 0.9842 - val_loss: 0.0399 - val_acc: 0.9843 - val_auc: 0.9988 - val_false_negatives: 24.0000 - val_false_positives: 57.0000 - val_true_negatives: 3156.0000 - val_true_positives: 1932.0000 - val_precision: 0.9713 - val_recall: 0.9877\n",
            "Epoch 60/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0326 - acc: 0.9892 - auc: 0.9988 - false_negatives: 175.0000 - false_positives: 141.0000 - true_negatives: 18309.0000 - true_positives: 10665.0000 - precision: 0.9870 - recall: 0.9839 - val_loss: 0.0435 - val_acc: 0.9874 - val_auc: 0.9976 - val_false_negatives: 21.0000 - val_false_positives: 44.0000 - val_true_negatives: 3169.0000 - val_true_positives: 1935.0000 - val_precision: 0.9778 - val_recall: 0.9893\n",
            "Epoch 61/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0340 - acc: 0.9890 - auc: 0.9986 - false_negatives: 175.0000 - false_positives: 147.0000 - true_negatives: 18303.0000 - true_positives: 10665.0000 - precision: 0.9864 - recall: 0.9839 - val_loss: 0.0337 - val_acc: 0.9896 - val_auc: 0.9980 - val_false_negatives: 25.0000 - val_false_positives: 29.0000 - val_true_negatives: 3184.0000 - val_true_positives: 1931.0000 - val_precision: 0.9852 - val_recall: 0.9872\n",
            "Epoch 62/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0311 - acc: 0.9896 - auc: 0.9988 - false_negatives: 164.0000 - false_positives: 140.0000 - true_negatives: 18310.0000 - true_positives: 10676.0000 - precision: 0.9871 - recall: 0.9849 - val_loss: 0.0350 - val_acc: 0.9899 - val_auc: 0.9979 - val_false_negatives: 26.0000 - val_false_positives: 26.0000 - val_true_negatives: 3187.0000 - val_true_positives: 1930.0000 - val_precision: 0.9867 - val_recall: 0.9867\n",
            "Epoch 63/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0303 - acc: 0.9897 - auc: 0.9989 - false_negatives: 169.0000 - false_positives: 134.0000 - true_negatives: 18316.0000 - true_positives: 10671.0000 - precision: 0.9876 - recall: 0.9844 - val_loss: 0.0371 - val_acc: 0.9890 - val_auc: 0.9971 - val_false_negatives: 33.0000 - val_false_positives: 24.0000 - val_true_negatives: 3189.0000 - val_true_positives: 1923.0000 - val_precision: 0.9877 - val_recall: 0.9831\n",
            "Epoch 64/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0307 - acc: 0.9897 - auc: 0.9989 - false_negatives: 171.0000 - false_positives: 131.0000 - true_negatives: 18319.0000 - true_positives: 10669.0000 - precision: 0.9879 - recall: 0.9842 - val_loss: 0.0394 - val_acc: 0.9888 - val_auc: 0.9970 - val_false_negatives: 27.0000 - val_false_positives: 31.0000 - val_true_negatives: 3182.0000 - val_true_positives: 1929.0000 - val_precision: 0.9842 - val_recall: 0.9862\n",
            "Epoch 65/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0339 - acc: 0.9883 - auc: 0.9989 - false_negatives: 185.0000 - false_positives: 159.0000 - true_negatives: 18291.0000 - true_positives: 10655.0000 - precision: 0.9853 - recall: 0.9829 - val_loss: 0.0361 - val_acc: 0.9888 - val_auc: 0.9984 - val_false_negatives: 24.0000 - val_false_positives: 34.0000 - val_true_negatives: 3179.0000 - val_true_positives: 1932.0000 - val_precision: 0.9827 - val_recall: 0.9877\n",
            "Epoch 66/100\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.0322 - acc: 0.9893 - auc: 0.9988 - false_negatives: 165.0000 - false_positives: 149.0000 - true_negatives: 18301.0000 - true_positives: 10675.0000 - precision: 0.9862 - recall: 0.9848 - val_loss: 0.0446 - val_acc: 0.9851 - val_auc: 0.9970 - val_false_negatives: 23.0000 - val_false_positives: 54.0000 - val_true_negatives: 3159.0000 - val_true_positives: 1933.0000 - val_precision: 0.9728 - val_recall: 0.9882\n",
            "Epoch 67/100\n",
            "293/293 [==============================] - 12s 43ms/step - loss: 0.0316 - acc: 0.9898 - auc: 0.9988 - false_negatives: 162.0000 - false_positives: 137.0000 - true_negatives: 18313.0000 - true_positives: 10678.0000 - precision: 0.9873 - recall: 0.9851 - val_loss: 0.0386 - val_acc: 0.9880 - val_auc: 0.9977 - val_false_negatives: 30.0000 - val_false_positives: 32.0000 - val_true_negatives: 3181.0000 - val_true_positives: 1926.0000 - val_precision: 0.9837 - val_recall: 0.9847\n",
            "Epoch 68/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0301 - acc: 0.9904 - auc: 0.9989 - false_negatives: 156.0000 - false_positives: 125.0000 - true_negatives: 18325.0000 - true_positives: 10684.0000 - precision: 0.9884 - recall: 0.9856 - val_loss: 0.0345 - val_acc: 0.9899 - val_auc: 0.9980 - val_false_negatives: 26.0000 - val_false_positives: 26.0000 - val_true_negatives: 3187.0000 - val_true_positives: 1930.0000 - val_precision: 0.9867 - val_recall: 0.9867\n",
            "Epoch 69/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0308 - acc: 0.9899 - auc: 0.9989 - false_negatives: 165.0000 - false_positives: 130.0000 - true_negatives: 18320.0000 - true_positives: 10675.0000 - precision: 0.9880 - recall: 0.9848 - val_loss: 0.0372 - val_acc: 0.9890 - val_auc: 0.9977 - val_false_negatives: 26.0000 - val_false_positives: 31.0000 - val_true_negatives: 3182.0000 - val_true_positives: 1930.0000 - val_precision: 0.9842 - val_recall: 0.9867\n",
            "Epoch 70/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0290 - acc: 0.9906 - auc: 0.9990 - false_negatives: 144.0000 - false_positives: 131.0000 - true_negatives: 18319.0000 - true_positives: 10696.0000 - precision: 0.9879 - recall: 0.9867 - val_loss: 0.0443 - val_acc: 0.9861 - val_auc: 0.9971 - val_false_negatives: 23.0000 - val_false_positives: 49.0000 - val_true_negatives: 3164.0000 - val_true_positives: 1933.0000 - val_precision: 0.9753 - val_recall: 0.9882\n",
            "Epoch 71/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0296 - acc: 0.9901 - auc: 0.9989 - false_negatives: 155.0000 - false_positives: 136.0000 - true_negatives: 18314.0000 - true_positives: 10685.0000 - precision: 0.9874 - recall: 0.9857 - val_loss: 0.0380 - val_acc: 0.9886 - val_auc: 0.9975 - val_false_negatives: 23.0000 - val_false_positives: 36.0000 - val_true_negatives: 3177.0000 - val_true_positives: 1933.0000 - val_precision: 0.9817 - val_recall: 0.9882\n",
            "Epoch 72/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0282 - acc: 0.9910 - auc: 0.9989 - false_negatives: 137.0000 - false_positives: 128.0000 - true_negatives: 18322.0000 - true_positives: 10703.0000 - precision: 0.9882 - recall: 0.9874 - val_loss: 0.0344 - val_acc: 0.9896 - val_auc: 0.9982 - val_false_negatives: 24.0000 - val_false_positives: 30.0000 - val_true_negatives: 3183.0000 - val_true_positives: 1932.0000 - val_precision: 0.9847 - val_recall: 0.9877\n",
            "Epoch 73/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0290 - acc: 0.9906 - auc: 0.9988 - false_negatives: 150.0000 - false_positives: 126.0000 - true_negatives: 18324.0000 - true_positives: 10690.0000 - precision: 0.9884 - recall: 0.9862 - val_loss: 0.0353 - val_acc: 0.9903 - val_auc: 0.9974 - val_false_negatives: 24.0000 - val_false_positives: 26.0000 - val_true_negatives: 3187.0000 - val_true_positives: 1932.0000 - val_precision: 0.9867 - val_recall: 0.9877\n",
            "Epoch 74/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0294 - acc: 0.9903 - auc: 0.9991 - false_negatives: 153.0000 - false_positives: 130.0000 - true_negatives: 18320.0000 - true_positives: 10687.0000 - precision: 0.9880 - recall: 0.9859 - val_loss: 0.0355 - val_acc: 0.9892 - val_auc: 0.9980 - val_false_negatives: 24.0000 - val_false_positives: 32.0000 - val_true_negatives: 3181.0000 - val_true_positives: 1932.0000 - val_precision: 0.9837 - val_recall: 0.9877\n",
            "Epoch 75/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0285 - acc: 0.9907 - auc: 0.9989 - false_negatives: 146.0000 - false_positives: 127.0000 - true_negatives: 18323.0000 - true_positives: 10694.0000 - precision: 0.9883 - recall: 0.9865 - val_loss: 0.0417 - val_acc: 0.9888 - val_auc: 0.9966 - val_false_negatives: 26.0000 - val_false_positives: 32.0000 - val_true_negatives: 3181.0000 - val_true_positives: 1930.0000 - val_precision: 0.9837 - val_recall: 0.9867\n",
            "Epoch 76/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0304 - acc: 0.9904 - auc: 0.9988 - false_negatives: 150.0000 - false_positives: 132.0000 - true_negatives: 18318.0000 - true_positives: 10690.0000 - precision: 0.9878 - recall: 0.9862 - val_loss: 0.0392 - val_acc: 0.9899 - val_auc: 0.9977 - val_false_negatives: 34.0000 - val_false_positives: 18.0000 - val_true_negatives: 3195.0000 - val_true_positives: 1922.0000 - val_precision: 0.9907 - val_recall: 0.9826\n",
            "Epoch 77/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0271 - acc: 0.9908 - auc: 0.9992 - false_negatives: 150.0000 - false_positives: 120.0000 - true_negatives: 18330.0000 - true_positives: 10690.0000 - precision: 0.9889 - recall: 0.9862 - val_loss: 0.0461 - val_acc: 0.9867 - val_auc: 0.9974 - val_false_negatives: 48.0000 - val_false_positives: 21.0000 - val_true_negatives: 3192.0000 - val_true_positives: 1908.0000 - val_precision: 0.9891 - val_recall: 0.9755\n",
            "Epoch 78/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0294 - acc: 0.9903 - auc: 0.9989 - false_negatives: 151.0000 - false_positives: 132.0000 - true_negatives: 18318.0000 - true_positives: 10689.0000 - precision: 0.9878 - recall: 0.9861 - val_loss: 0.0379 - val_acc: 0.9888 - val_auc: 0.9977 - val_false_negatives: 27.0000 - val_false_positives: 31.0000 - val_true_negatives: 3182.0000 - val_true_positives: 1929.0000 - val_precision: 0.9842 - val_recall: 0.9862\n",
            "Epoch 79/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0310 - acc: 0.9898 - auc: 0.9989 - false_negatives: 166.0000 - false_positives: 134.0000 - true_negatives: 18316.0000 - true_positives: 10674.0000 - precision: 0.9876 - recall: 0.9847 - val_loss: 0.0379 - val_acc: 0.9892 - val_auc: 0.9974 - val_false_negatives: 34.0000 - val_false_positives: 22.0000 - val_true_negatives: 3191.0000 - val_true_positives: 1922.0000 - val_precision: 0.9887 - val_recall: 0.9826\n",
            "Epoch 80/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0285 - acc: 0.9907 - auc: 0.9990 - false_negatives: 143.0000 - false_positives: 129.0000 - true_negatives: 18321.0000 - true_positives: 10697.0000 - precision: 0.9881 - recall: 0.9868 - val_loss: 0.0389 - val_acc: 0.9874 - val_auc: 0.9981 - val_false_negatives: 25.0000 - val_false_positives: 40.0000 - val_true_negatives: 3173.0000 - val_true_positives: 1931.0000 - val_precision: 0.9797 - val_recall: 0.9872\n",
            "Epoch 81/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0286 - acc: 0.9910 - auc: 0.9991 - false_negatives: 156.0000 - false_positives: 107.0000 - true_negatives: 18343.0000 - true_positives: 10684.0000 - precision: 0.9901 - recall: 0.9856 - val_loss: 0.0416 - val_acc: 0.9880 - val_auc: 0.9975 - val_false_negatives: 28.0000 - val_false_positives: 34.0000 - val_true_negatives: 3179.0000 - val_true_positives: 1928.0000 - val_precision: 0.9827 - val_recall: 0.9857\n",
            "Epoch 82/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0275 - acc: 0.9906 - auc: 0.9991 - false_negatives: 149.0000 - false_positives: 127.0000 - true_negatives: 18323.0000 - true_positives: 10691.0000 - precision: 0.9883 - recall: 0.9863 - val_loss: 0.0386 - val_acc: 0.9899 - val_auc: 0.9972 - val_false_negatives: 30.0000 - val_false_positives: 22.0000 - val_true_negatives: 3191.0000 - val_true_positives: 1926.0000 - val_precision: 0.9887 - val_recall: 0.9847\n",
            "Epoch 83/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0274 - acc: 0.9913 - auc: 0.9990 - false_negatives: 149.0000 - false_positives: 107.0000 - true_negatives: 18343.0000 - true_positives: 10691.0000 - precision: 0.9901 - recall: 0.9863 - val_loss: 0.0412 - val_acc: 0.9888 - val_auc: 0.9971 - val_false_negatives: 28.0000 - val_false_positives: 30.0000 - val_true_negatives: 3183.0000 - val_true_positives: 1928.0000 - val_precision: 0.9847 - val_recall: 0.9857\n",
            "Epoch 84/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0270 - acc: 0.9915 - auc: 0.9991 - false_negatives: 146.0000 - false_positives: 103.0000 - true_negatives: 18347.0000 - true_positives: 10694.0000 - precision: 0.9905 - recall: 0.9865 - val_loss: 0.0381 - val_acc: 0.9894 - val_auc: 0.9978 - val_false_negatives: 23.0000 - val_false_positives: 32.0000 - val_true_negatives: 3181.0000 - val_true_positives: 1933.0000 - val_precision: 0.9837 - val_recall: 0.9882\n",
            "Epoch 85/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0260 - acc: 0.9911 - auc: 0.9991 - false_negatives: 152.0000 - false_positives: 108.0000 - true_negatives: 18342.0000 - true_positives: 10688.0000 - precision: 0.9900 - recall: 0.9860 - val_loss: 0.0399 - val_acc: 0.9888 - val_auc: 0.9974 - val_false_negatives: 22.0000 - val_false_positives: 36.0000 - val_true_negatives: 3177.0000 - val_true_positives: 1934.0000 - val_precision: 0.9817 - val_recall: 0.9888\n",
            "Epoch 86/100\n",
            "293/293 [==============================] - 12s 42ms/step - loss: 0.0262 - acc: 0.9912 - auc: 0.9990 - false_negatives: 142.0000 - false_positives: 115.0000 - true_negatives: 18335.0000 - true_positives: 10698.0000 - precision: 0.9894 - recall: 0.9869 - val_loss: 0.0377 - val_acc: 0.9892 - val_auc: 0.9981 - val_false_negatives: 25.0000 - val_false_positives: 31.0000 - val_true_negatives: 3182.0000 - val_true_positives: 1931.0000 - val_precision: 0.9842 - val_recall: 0.9872\n",
            "Epoch 87/100\n",
            "293/293 [==============================] - 12s 41ms/step - loss: 0.0310 - acc: 0.9898 - auc: 0.9989 - false_negatives: 183.0000 - false_positives: 115.0000 - true_negatives: 18335.0000 - true_positives: 10657.0000 - precision: 0.9893 - recall: 0.9831 - val_loss: 0.0408 - val_acc: 0.9878 - val_auc: 0.9970 - val_false_negatives: 22.0000 - val_false_positives: 41.0000 - val_true_negatives: 3172.0000 - val_true_positives: 1934.0000 - val_precision: 0.9792 - val_recall: 0.9888\n",
            "Epoch 87: early stopping\n"
          ]
        }
      ],
      "source": [
        "Xx=all_train_data['sequence_numbers'].values  #trajectories\n",
        "Y=all_train_data['label'].values\n",
        "\n",
        "max_length = 200\n",
        "X = pad_sequences(Xx, maxlen=max_length, padding='post')  ## fill 0s\n",
        "# Split data into 85% training & 15% test\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_validation.shape, y_validation.shape)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "x_validation=x_validation.reshape(x_validation.shape[0],x_validation.shape[1],1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_validation.shape, y_validation.shape)\n",
        "\n",
        "x_train=np.asarray(x_train).astype(np.int)\n",
        "y_train=np.asarray(y_train).astype(np.int)\n",
        "\n",
        "x_validation=np.asarray(x_validation).astype(np.int)\n",
        "y_validation=np.asarray(y_validation).astype(np.int)\n",
        "\n",
        "\n",
        "# build the neural network\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, return_sequences = True, input_shape = (x_train.shape[1],1 )))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "model.add(LSTM(75,return_sequences = True))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "model.add(LSTM(75,return_sequences = True))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "es = EarlyStopping(monitor='auc', mode='max', patience=10, verbose=1) ## patience can be varied\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",metrics=[\"acc\",\"AUC\",\"FalseNegatives\",\"FalsePositives\",\"TrueNegatives\",\"TruePositives\",\"Precision\",\"Recall\"])\n",
        "history = model.fit(x = x_train, y = y_train,callbacks=[es], validation_data=(x_validation, y_validation), batch_size = 100, epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eU2x-fw-wNrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4957c17b-73cb-47dd-e8a4-c7307c44deca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 4s 23ms/step - loss: 0.0475 - acc: 0.9866 - auc: 0.9966 - false_negatives: 33.0000 - false_positives: 62.0000 - true_negatives: 3574.0000 - true_positives: 3401.0000 - precision: 0.9821 - recall: 0.9904\n",
            "[0.047525350004434586, 0.986562967300415, 0.996616005897522, 33.0, 62.0, 3574.0, 3401.0, 0.9820964336395264, 0.9903902411460876]\n"
          ]
        }
      ],
      "source": [
        "x_test = all_test_data['sequence_numbers'].values  #trajectories\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post')  ## fill 0s\n",
        "y_test = all_test_data['label'].values\n",
        "\n",
        "x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "y_test=np.asarray(y_test).astype(np.int)\n",
        "\n",
        "results = model.evaluate(x_test, y_test, batch_size=100)  #model evaluation on the test set\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratified Cross validation"
      ],
      "metadata": {
        "id": "cng4dR0zzsrl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWcajVP-Zp1W"
      },
      "outputs": [],
      "source": [
        "X=data_train['sequence_numbers'].values\n",
        "y=data_train['label'].values\n",
        "\n",
        "y=np.asarray(y).astype(np.int)\n",
        "max_length = 200\n",
        "#X = pad_sequences(Xx, maxlen=max_length, padding='post')\n",
        "\n",
        "#metrics\n",
        "Acc =[]\n",
        "Pre =[]\n",
        "Rec = []\n",
        "Auc = []\n",
        "F1 =[]\n",
        "FI =[]\n",
        "TPR = []\n",
        "TNR = []\n",
        "Loss=[]\n",
        "\n",
        "# Instantiate the cross validator\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# Loop through the indices the split() method returns\n",
        "for index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n",
        "\n",
        "    # Generate batches from indices\n",
        "    x_train, x_test = X[train_indices], X[val_indices]\n",
        "    y_train, y_test = y[train_indices], y[val_indices]\n",
        "\n",
        "    x_train_df = pd.DataFrame(columns = ['sequence_numbers', 'label'])\n",
        "    for j in range(len(x_train)):\n",
        "      x_train_df.loc[j] = [x_train[j], y_train[j]]\n",
        "\n",
        "    x_test_df = pd.DataFrame(columns = ['sequence_numbers', 'label'])\n",
        "    for j in range(len(x_test)):\n",
        "      x_test_df.loc[j] =  [x_test[j], y_test[j]]\n",
        "\n",
        "    #preparing the splitted sequences of trainig users/trolls\n",
        "    users = x_train_df[x_train_df['label']==0].reset_index(drop=True)\n",
        "    trolls = x_train_df[x_train_df['label']==1].reset_index(drop=True)\n",
        "    max_length = 200 #trajectory Length: L. LSTM input\n",
        "    new_data = pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "    count=0\n",
        "    #users\n",
        "    #iterating over users from training set\n",
        "    for i in range(len(users)):\n",
        "      user = users.loc[i]\n",
        "      traj = users.loc[i]['sequence_numbers']\n",
        "      l = len(traj)\n",
        "\n",
        "      if l <= max_length: #if trajectory length less then max_lenght add it as it is\n",
        "        res=traj\n",
        "        new_data.loc[count]=[res,0] # label 0 for users\n",
        "        count=count+1\n",
        "\n",
        "      else:  #else split it into records\n",
        "        res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "        for j in range(len(res)):\n",
        "          new_data.loc[count]=[res[j].tolist(),0] # label 0 for users\n",
        "          count=count+1\n",
        "          \n",
        "    new_data_trolls=pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "\n",
        "    count=0\n",
        "    #trolls\n",
        "    #iterating over trolls from training set\n",
        "    for i in range(len(trolls)):\n",
        "      troll=trolls.loc[i]\n",
        "      traj = trolls.loc[i]['sequence_numbers']\n",
        "      l = len(traj)\n",
        "\n",
        "      if l <= max_length:  #if trajectory length less then max_lenght add it as it is\n",
        "        res=traj\n",
        "        new_data_trolls.loc[count]=[res,1]\n",
        "        count=count+1\n",
        "\n",
        "      else: #else split it into records\n",
        "        res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "        for j in range(len(res)):\n",
        "          new_data_trolls.loc[count]=[res[j].tolist(),1]\n",
        "          count=count+1\n",
        "\n",
        "    #all_data is the dataframe that contains the extracted sequences of users and trolls from train set\n",
        "    frames = [new_data, new_data_trolls]\n",
        "    all_train_data_skf = pd.concat(frames)\n",
        "    all_train_data_skf = all_train_data_skf.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    #preparing the splitted sequences of test users/trolls\n",
        "    users = x_test_df[x_test_df['label']==0].reset_index(drop=True)\n",
        "    trolls = x_test_df[x_test_df['label']==1].reset_index(drop=True)\n",
        "    max_length = 200 #trajectory Length: L. LSTM input\n",
        "    new_data = pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "    count=0\n",
        "    #users\n",
        "    #iterating over users from training set\n",
        "    for i in range(len(users)):\n",
        "      user = users.loc[i]\n",
        "      traj = users.loc[i]['sequence_numbers']\n",
        "      l = len(traj)\n",
        "\n",
        "      if l <= max_length: #if trajectory length less then max_lenght add it as it is\n",
        "        res=traj\n",
        "        new_data.loc[count]=[res,0] # label 0 for users\n",
        "        count=count+1\n",
        "\n",
        "      else:  #else split it into records\n",
        "        res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "        for j in range(len(res)):\n",
        "          new_data.loc[count]=[res[j].tolist(),0] # label 0 for users\n",
        "          count=count+1\n",
        "          \n",
        "    new_data_trolls=pd.DataFrame(columns=['sequence_numbers','label'])\n",
        "\n",
        "    count=0\n",
        "    #trolls\n",
        "    #iterating over trolls from training set\n",
        "    for i in range(len(trolls)):\n",
        "      troll=trolls.loc[i]\n",
        "      traj = trolls.loc[i]['sequence_numbers']\n",
        "      l = len(traj)\n",
        "\n",
        "      if l <= max_length:  #if trajectory length less then max_lenght add it as it is\n",
        "        res=traj\n",
        "        new_data_trolls.loc[count]=[res,1]\n",
        "        count=count+1\n",
        "\n",
        "      else: #else split it into records\n",
        "        res = np.array_split(traj[0:(len(traj)-len(traj)%max_length)],len(traj)/max_length)\n",
        "        for j in range(len(res)):\n",
        "          new_data_trolls.loc[count]=[res[j].tolist(),1]\n",
        "          count=count+1\n",
        "\n",
        "    #all_data is the dataframe that contains the extracted sequences of users and trolls from train set\n",
        "    frames = [new_data, new_data_trolls]\n",
        "    all_test_data_skf = pd.concat(frames)\n",
        "    all_test_data_skf = all_train_data_skf.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "    x_train = all_train_data_skf['sequence_numbers'].values\n",
        "    x_train = pad_sequences(x_train, maxlen=max_length, padding='post')\n",
        "    y_train = all_train_data_skf['label'].values\n",
        "\n",
        "    x_test = all_test_data_skf['sequence_numbers'].values\n",
        "    x_test = pad_sequences(x_test, maxlen=max_length, padding='post')\n",
        "    y_test = all_test_data_skf['label'].values\n",
        "\n",
        "\n",
        "    x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "    x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "\n",
        "    x_train=np.asarray(x_train).astype(np.int)\n",
        "    y_train=np.asarray(y_train).astype(np.int)\n",
        "\n",
        "    x_test=np.asarray(x_test).astype(np.int)\n",
        "    y_test=np.asarray(y_test).astype(np.int)\n",
        "\n",
        "\n",
        "    \n",
        "    # build the neural network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(100, return_sequences = True, input_shape = (x_train.shape[1],1 )))\n",
        "    model.add(Dropout(rate = 0.2))\n",
        "    model.add(LSTM(75,return_sequences = True))\n",
        "    model.add(Dropout(rate = 0.2))\n",
        "    model.add(LSTM(75,return_sequences = True))\n",
        "    model.add(Dropout(rate = 0.2))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dropout(rate = 0.2))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    #es = EarlyStopping(monitor='auc', mode='max', patience=20, verbose=1)\n",
        "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",metrics=[\"acc\",\"AUC\",\"FalseNegatives\",\"FalsePositives\",\"TrueNegatives\",\"TruePositives\",\"Precision\",\"Recall\"])\n",
        "    model.fit(x = x_train, y = y_train, batch_size = 64,verbose=1, epochs = 30)\n",
        "    history = model.evaluate(x_test, y_test, batch_size=100)\n",
        "    Loss.append(history[0])\n",
        "\n",
        "    acc= history[1]\n",
        "    Acc.append(acc)\n",
        "\n",
        "    auc = history[2]\n",
        "    Auc.append(auc)\n",
        "\n",
        "    fn= history[3]\n",
        "    fp = history[4]\n",
        "    tn = history[5]\n",
        "    tp = history[6]\n",
        "\n",
        "\n",
        "    tpr = tp/float(tp+fn)\n",
        "    tnr = tn/float(tn+fp)\n",
        "\n",
        "    TPR.append(tpr)\n",
        "    TNR.append(tnr)\n",
        "\n",
        "    prec= history[7]\n",
        "    Pre.append(prec)\n",
        "\n",
        "    rec = history[8]\n",
        "    Rec.append(rec)\n",
        "    try:\n",
        "      f1 = 2 * ((prec*rec)/(prec+rec))\n",
        "    except ZeroDivisionError:\n",
        "      f1 = 0\n",
        "    F1.append(f1)\n",
        "\n",
        "print(\"LSTM With Trajectory classification\")\n",
        "print(\"accuracy\",np.mean(Acc),np.std(Acc))\n",
        "print(\"precision\",np.mean(Pre),np.std(Pre))\n",
        "print(\"recall\",np.mean(Rec),np.std(Rec))\n",
        "print(\"f1\",np.mean(F1),np.std(F1))\n",
        "print(\"AUC\",np.mean(Auc),np.std(Auc))\n",
        "print(\"TPR\",np.mean(TPR),np.std(TPR))\n",
        "print(\"TNR\",np.mean(TNR),np.std(TNR))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Troll Score Computation and CDF plot"
      ],
      "metadata": {
        "id": "IHdh08_Y0koi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### sliding window validation\n",
        "\n",
        "### troll score classification:  e.g: input [0, 0, 0, 0, 0], mask [1, 1, 1, 1, 1] => troll score is the number of matched 1's\n",
        "\n",
        "max_length=200\n",
        "\n",
        "output=pd.DataFrame(columns=['screen_name','sequence_numbers','label','troll_score'])\n",
        "\n",
        "counter=0\n",
        "users_acc=[]\n",
        "trolls_acc=[]\n",
        "\n",
        "users = data_test[data_test['label']==0].reset_index(drop=True)\n",
        "trolls = data_test[data_test['label']==1].reset_index(drop=True)\n",
        "\n",
        "#computing the troll score for the users\n",
        "#sliding window\n",
        "#compute the ratio of how many time the sequences classified as troll\n",
        "\n",
        "for i in range(len(users)):\n",
        "  user=users.loc[i]\n",
        "  traj = users.loc[i]['sequence_numbers']\n",
        "  l = len(traj)\n",
        "\n",
        "  if l <= max_length:  # data used in the training will be ignored\n",
        "    res=traj   #then do nothing\n",
        "\n",
        "  else:\n",
        "    res=[]\n",
        "    for j in range(l-max_length -1):\n",
        "      #if j%max_length ==0:     #data used in the training will be ignored\n",
        "      #  continue\n",
        "      res.append(traj[j:j+max_length])\n",
        "\n",
        "    if len(res) > 0:\n",
        "      x_test = pad_sequences(res, maxlen=max_length, padding='post')\n",
        "      x_test= x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "      y_test=np.asarray([1]*len(x_test)).astype(np.int)  \n",
        "      history = model.evaluate(x_test, y_test, batch_size=100)\n",
        "      output.loc[counter]=[user['screen_name'],user['sequence_numbers'],0,history[1]]\n",
        "      counter = counter+1\n",
        "      users_acc.append(history[1])\n",
        "\n",
        "#computing the troll score for the trolls\n",
        "#sliding window\n",
        "#compute the ratio of how many time the sequences classified as troll\n",
        "counter =0\n",
        "for i in range(len(trolls)):\n",
        "  troll=trolls.loc[i]\n",
        "  traj = trolls.loc[i]['sequence_numbers']\n",
        "  l = len(traj)\n",
        "\n",
        "  if l <= max_length:  \n",
        "    res=traj   #do nothing because data used in the training\n",
        "\n",
        "  else:\n",
        "    res=[]\n",
        "    for j in range(l- max_length -1):\n",
        "      #if j%max_length == 0:     #data used in the training will be ignored\n",
        "      #  continue\n",
        "      res.append(traj[j:j+max_length])\n",
        "    if len(res) > 0:\n",
        "      x_test = pad_sequences(res, maxlen=max_length, padding='post')\n",
        "      x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "      y_test=np.asarray([1]*len(x_test)).astype(np.int)\n",
        "      history = model.evaluate(x_test, y_test, batch_size=100)\n",
        "      output.loc[counter]=[user['screen_name'],user['sequence_numbers'],1,history[1]]\n",
        "      counter=counter+1\n",
        "      trolls_acc.append(history[1])"
      ],
      "metadata": {
        "id": "_Lx1OxyB0hxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88a3790-7e3b-4261-eaff-0c38a2e45345"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3/23 [==>...........................] - ETA: 0s - loss: 6.9819 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 300.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 1s 24ms/step - loss: 10.0477 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2279.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 9.8150 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2912.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "33/33 [==============================] - 1s 19ms/step - loss: 9.1571 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3256.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 10.9606 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 288.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "53/53 [==============================] - 1s 19ms/step - loss: 10.7769 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5204.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 11.0775 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1276.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 11.0599 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2391.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 11.1240 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1109.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11.0138 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 438.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 11.1812 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2684.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "28/28 [==============================] - 1s 18ms/step - loss: 4.2771 - acc: 0.1458 - auc: 0.0000e+00 - false_negatives: 2349.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 401.0000 - precision: 1.0000 - recall: 0.1458\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.1140 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 535.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 11.2440 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5576.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11.1642 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 731.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 10.1319 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1117.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 10.9541 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2313.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 6.0967 - acc: 0.0950 - auc: 0.0000e+00 - false_negatives: 467.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 49.0000 - precision: 1.0000 - recall: 0.0950\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.1668 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 517.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "36/36 [==============================] - 1s 17ms/step - loss: 11.2048 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3570.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 10.2309 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 408.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6.0471 - acc: 0.0249 - auc: 0.0000e+00 - false_negatives: 705.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 18.0000 - precision: 1.0000 - recall: 0.0249\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6836 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 532.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 7.4730 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 231.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.2629 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 49.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 10.4286 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 603.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 8.2673 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1465.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "139/139 [==============================] - 3s 20ms/step - loss: 11.1403 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 13804.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 11.1972 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 208.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 8.8719 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2396.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 10.2043 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 10896.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 11.1732 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 950.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 10.0678 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 848.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 9.3498 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 931.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 10.4614 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1161.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 11.3025 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3001.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 11.0527 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1490.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 11.2882 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4471.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 11.0874 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 498.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "141/141 [==============================] - 2s 17ms/step - loss: 10.1454 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 14090.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.9005 - acc: 0.0120 - auc: 0.0000e+00 - false_negatives: 493.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 6.0000 - precision: 1.0000 - recall: 0.0120\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 10.9314 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1402.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 7.1323 - acc: 0.0348 - auc: 0.0000e+00 - false_negatives: 611.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 22.0000 - precision: 1.0000 - recall: 0.0348          \n",
            "10/10 [==============================] - 0s 17ms/step - loss: 4.2449 - acc: 0.3265 - auc: 0.0000e+00 - false_negatives: 627.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 304.0000 - precision: 1.0000 - recall: 0.3265\n",
            "75/75 [==============================] - 1s 18ms/step - loss: 7.2570 - acc: 0.0173 - auc: 0.0000e+00 - false_negatives: 7363.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 130.0000 - precision: 1.0000 - recall: 0.0173\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 10.7962 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2290.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 11.2205 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 198.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 11.1218 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 810.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 11.1742 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6054.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 11.0413 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2104.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "121/121 [==============================] - 2s 19ms/step - loss: 6.7571 - acc: 8.2994e-05 - auc: 0.0000e+00 - false_negatives: 12048.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 1.0000 - precision: 1.0000 - recall: 8.2994e-05\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8434 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 524.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 10.5569 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4390.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 10.9093 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 9858.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "36/36 [==============================] - 1s 17ms/step - loss: 6.8071 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3510.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.9708 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 195.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.1937 - acc: 0.0756 - auc: 0.0000e+00 - false_negatives: 648.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 53.0000 - precision: 1.0000 - recall: 0.0756\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 11.0156 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5955.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "36/36 [==============================] - 1s 17ms/step - loss: 11.1245 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3519.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "77/77 [==============================] - 1s 17ms/step - loss: 10.8278 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7633.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 11.2877 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7967.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 10.5531 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1373.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "197/197 [==============================] - 3s 18ms/step - loss: 11.1022 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 19634.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 11.2988 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1807.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8133 - acc: 0.1579 - auc: 0.0000e+00 - false_negatives: 16.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 3.0000 - precision: 1.0000 - recall: 0.1579\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.8668 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 183.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11.2067 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 748.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 7.5661 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 280.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 7.7413 - acc: 3.3818e-04 - auc: 0.0000e+00 - false_negatives: 2956.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 1.0000 - precision: 1.0000 - recall: 3.3818e-04\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 7.2333 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 264.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "43/43 [==============================] - 1s 19ms/step - loss: 11.3103 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4284.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 10.8577 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7266.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "39/39 [==============================] - 1s 18ms/step - loss: 10.9044 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3874.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 10.9194 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1075.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 11.0855 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3006.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 11.1934 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3059.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 5.8186 - acc: 0.0734 - auc: 0.0000e+00 - false_negatives: 2348.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 186.0000 - precision: 1.0000 - recall: 0.0734\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 9.9575 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4622.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 8.9978 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1398.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7192 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 41.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 11.2789 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1663.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 7.9432 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7073.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 9.8880 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 971.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 11.0995 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 930.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 10.0566 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1032.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 11.2049 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1322.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "33/33 [==============================] - 1s 18ms/step - loss: 8.4715 - acc: 0.0269 - auc: 0.0000e+00 - false_negatives: 3187.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 88.0000 - precision: 1.0000 - recall: 0.0269\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 5.2365 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 718.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 10.7826 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 239.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 11.0113 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2493.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.0279 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 837.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "247/247 [==============================] - 4s 18ms/step - loss: 6.8429 - acc: 0.0264 - auc: 0.0000e+00 - false_negatives: 24017.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 651.0000 - precision: 1.0000 - recall: 0.0264\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 10.3223 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 461.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.9299 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 961.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "114/114 [==============================] - 2s 18ms/step - loss: 11.2354 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 11349.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.9262 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 14.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 6.4926 - acc: 0.0134 - auc: 0.0000e+00 - false_negatives: 3098.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 42.0000 - precision: 1.0000 - recall: 0.0134\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 10.5181 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1400.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 10.2161 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1115.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 10.3100 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1149.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 11.2030 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1701.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 11.2356 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 919.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 10.8889 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 735.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 11.1289 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1590.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 11.2911 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4394.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 11.2142 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3466.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 8.1271 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 487.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 6.7518 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 236.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.3329 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 478.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "179/179 [==============================] - 3s 18ms/step - loss: 2.1370 - acc: 0.3504 - auc: 0.0000e+00 - false_negatives: 11594.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 6253.0000 - precision: 1.0000 - recall: 0.3504\n",
            "42/42 [==============================] - 1s 18ms/step - loss: 8.3685 - acc: 0.0746 - auc: 0.0000e+00 - false_negatives: 3846.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 310.0000 - precision: 1.0000 - recall: 0.0746\n",
            "21/21 [==============================] - 0s 18ms/step - loss: 11.0008 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2096.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 10.8361 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 350.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 8.8209 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1410.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 11.1834 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1378.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 11.1371 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7883.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11.0128 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 89.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 11.3016 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2464.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.0871 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 73.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 10.8298 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 197.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.6658 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 11.2858 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1204.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 11.2097 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5995.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 8.4439 - acc: 0.0349 - auc: 0.0000e+00 - false_negatives: 1604.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 58.0000 - precision: 1.0000 - recall: 0.0349\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 11.1208 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 8638.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 9.0085 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1756.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.8557 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 69.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 8.7637 - acc: 0.0397 - auc: 0.0000e+00 - false_negatives: 4282.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 177.0000 - precision: 1.0000 - recall: 0.0397\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.5102 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 574.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 11.2931 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1960.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 10.9248 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3512.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 10.9321 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 250.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 9.7483 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 500.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 9.7362 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 9753.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10.8779 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 748.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 9.8296 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 698.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.5445 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 19.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.2748 - acc: 0.0349 - auc: 0.0000e+00 - false_negatives: 856.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 31.0000 - precision: 1.0000 - recall: 0.0349\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 10.3394 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2593.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 9.7016 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2394.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 11.3035 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3029.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2153 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 24.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 11.1100 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3080.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 8.6227 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 221.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "21/21 [==============================] - 0s 18ms/step - loss: 10.0553 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2054.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 10.6555 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 802.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 11.2735 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1638.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 9.9250 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6106.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 10.9811 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 112.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 11.2389 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 271.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 10.6120 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1635.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 11.1290 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3647.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 11.0909 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1647.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 11.2306 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4717.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 10.1828 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7091.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 11.1147 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5747.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 11.2948 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 4055.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 8.3712 - acc: 4.1964e-04 - auc: 0.0000e+00 - false_negatives: 2382.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 1.0000 - precision: 1.0000 - recall: 4.1964e-04\n",
            "69/69 [==============================] - 1s 18ms/step - loss: 8.9319 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6813.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 11.0200 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2649.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "68/68 [==============================] - 1s 18ms/step - loss: 10.7269 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6739.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.5134 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 94.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 11.2019 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 42204.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 9.9913 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 981.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 8.9666 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1805.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "64/64 [==============================] - 1s 18ms/step - loss: 10.4279 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6330.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 10.4252 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 658.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 5.7010 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1326.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.8480 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 407.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 8.7053 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 11475.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 6.7427 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 108.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 11.2010 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1187.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "33/33 [==============================] - 1s 18ms/step - loss: 11.2917 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3240.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 11.0853 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2834.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 10.2314 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 604.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "80/80 [==============================] - 1s 18ms/step - loss: 11.2989 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7945.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 11.0435 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5713.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 10.7624 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3415.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 11.3014 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1766.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.1453 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 922.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 10.3003 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 400.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 11.1810 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2607.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5010 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 576.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 8.2474 - acc: 1.6075e-04 - auc: 0.0000e+00 - false_negatives: 6220.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 1.0000 - precision: 1.0000 - recall: 1.6075e-04\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 11.1970 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 8509.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 3.6798 - acc: 0.3237 - auc: 0.0000e+00 - false_negatives: 1701.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 814.0000 - precision: 1.0000 - recall: 0.3237\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 11.1317 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 693.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.8513 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2652.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4252 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 20.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 5.3465 - acc: 0.0382 - auc: 0.0000e+00 - false_negatives: 4257.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 169.0000 - precision: 1.0000 - recall: 0.0382\n",
            "68/68 [==============================] - 1s 18ms/step - loss: 10.8164 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6752.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 9.7329 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 10658.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 10.8347 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1652.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 11.1843 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1285.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1326 - acc: 0.1754 - auc: 0.0000e+00 - false_negatives: 47.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 10.0000 - precision: 1.0000 - recall: 0.1754\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 10.0636 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 14309.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.8331 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 705.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 10.4608 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2629.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 10.8162 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 234.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 9.8282 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 319.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 5.1379 - acc: 0.1362 - auc: 0.0000e+00 - false_negatives: 1921.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 303.0000 - precision: 1.0000 - recall: 0.1362\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 10.4615 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5010.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.1035 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 95.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 11.0938 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3446.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 11.2863 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1570.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 11.1125 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1544.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.3833 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 298.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.3747 - acc: 0.0236 - auc: 0.0000e+00 - false_negatives: 785.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 19.0000 - precision: 1.0000 - recall: 0.0236\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 9.5820 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 7839.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 10.8177 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 6967.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 7.7497 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 3682.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "104/104 [==============================] - 2s 18ms/step - loss: 10.2892 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 10332.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 10.5279 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 977.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 11.2024 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 685.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6.0403 - acc: 0.0599 - auc: 0.0000e+00 - false_negatives: 706.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 45.0000 - precision: 1.0000 - recall: 0.0599\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11.1712 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 773.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 6.8686 - acc: 0.0712 - auc: 0.0000e+00 - false_negatives: 4412.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 338.0000 - precision: 1.0000 - recall: 0.0712\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 8.3803 - acc: 0.0721 - auc: 0.0000e+00 - false_negatives: 1827.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 142.0000 - precision: 1.0000 - recall: 0.0721\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.5857 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 1102.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 7.6387 - acc: 0.0052 - auc: 0.0000e+00 - false_negatives: 569.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 3.0000 - precision: 1.0000 - recall: 0.0052           \n",
            "27/27 [==============================] - 1s 18ms/step - loss: 9.9897 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 2615.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 11.1884 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5389.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 6.6822 - acc: 0.0966 - auc: 0.0000e+00 - false_negatives: 1402.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 150.0000 - precision: 1.0000 - recall: 0.0966\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 10.9175 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 432.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1299 - acc: 0.9388 - auc: 0.0000e+00 - false_negatives: 3.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 46.0000 - precision: 1.0000 - recall: 0.9388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return asarray(a).ndim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "913/913 [==============================] - 16s 17ms/step - loss: 0.0071 - acc: 0.9977 - auc: 0.0000e+00 - false_negatives: 213.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 91070.0000 - precision: 1.0000 - recall: 0.9977\n",
            "893/893 [==============================] - 16s 18ms/step - loss: 0.0147 - acc: 0.9960 - auc: 0.0000e+00 - false_negatives: 358.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 88909.0000 - precision: 1.0000 - recall: 0.9960\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0854 - acc: 0.9601 - auc: 0.0000e+00 - false_negatives: 14.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 337.0000 - precision: 1.0000 - recall: 0.9601\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2727 - acc: 0.9420 - auc: 0.0000e+00 - false_negatives: 219.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 3555.0000 - precision: 1.0000 - recall: 0.9420\n",
            "3722/3722 [==============================] - 65s 17ms/step - loss: 0.0112 - acc: 0.9967 - auc: 0.0000e+00 - false_negatives: 1237.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 370901.0000 - precision: 1.0000 - recall: 0.9967\n",
            "6/6 [==============================] - 2s 433ms/step - loss: 0.1584 - acc: 0.9447 - auc: 0.0000e+00 - false_negatives: 29.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 495.0000 - precision: 1.0000 - recall: 0.9447\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 9.9067e-04 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 6974.0000 - precision: 1.0000 - recall: 1.0000\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.0017 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 7362.0000 - precision: 1.0000 - recall: 1.0000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0222 - acc: 0.9889 - auc: 0.0000e+00 - false_negatives: 5.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 445.0000 - precision: 1.0000 - recall: 0.9889\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2202 - acc: 0.9396 - auc: 0.0000e+00 - false_negatives: 16.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 249.0000 - precision: 1.0000 - recall: 0.9396\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.8928 - acc: 0.3851 - auc: 0.0000e+00 - false_negatives: 364.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 228.0000 - precision: 1.0000 - recall: 0.3851\n",
            "49/49 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 4814.0000 - precision: 1.0000 - recall: 1.0000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1888 - acc: 0.9083 - auc: 0.0000e+00 - false_negatives: 41.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 406.0000 - precision: 1.0000 - recall: 0.9083\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3453 - acc: 0.8355 - auc: 0.0000e+00 - false_negatives: 103.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 523.0000 - precision: 1.0000 - recall: 0.8355\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.6115 - acc: 0.3144 - auc: 0.0000e+00 - false_negatives: 181.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 83.0000 - precision: 1.0000 - recall: 0.3144          \n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 3758.0000 - precision: 1.0000 - recall: 1.0000\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.0786 - acc: 0.9711 - auc: 0.0000e+00 - false_negatives: 710.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 23896.0000 - precision: 1.0000 - recall: 0.9711\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.5313 - acc: 0.8141 - auc: 0.0000e+00 - false_negatives: 132.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 578.0000 - precision: 1.0000 - recall: 0.8141\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.0013 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 5365.0000 - precision: 1.0000 - recall: 1.0000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9705 - acc: 0.8168 - auc: 0.0000e+00 - false_negatives: 61.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 272.0000 - precision: 1.0000 - recall: 0.8168\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 17.0000 - precision: 1.0000 - recall: 1.0000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 26.0000 - precision: 1.0000 - recall: 1.0000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.2035 - acc: 0.6848 - auc: 0.0000e+00 - false_negatives: 52.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 113.0000 - precision: 1.0000 - recall: 0.6848\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.5806e-04 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 4.0000 - precision: 1.0000 - recall: 1.0000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1231 - acc: 0.9477 - auc: 0.0000e+00 - false_negatives: 15.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 272.0000 - precision: 1.0000 - recall: 0.9477\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7675 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 5.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.2292 - acc: 0.1144 - auc: 0.0000e+00 - false_negatives: 240.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 31.0000 - precision: 1.0000 - recall: 0.1144\n",
            "138/138 [==============================] - 2s 17ms/step - loss: 0.0013 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 13729.0000 - precision: 1.0000 - recall: 1.0000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0438 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 147.0000 - precision: 1.0000 - recall: 1.0000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0066 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 258.0000 - precision: 1.0000 - recall: 1.0000\n",
            "124/124 [==============================] - 2s 17ms/step - loss: 0.0066 - acc: 0.9987 - auc: 0.0000e+00 - false_negatives: 16.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 12329.0000 - precision: 1.0000 - recall: 0.9987\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.0012 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 4705.0000 - precision: 1.0000 - recall: 1.0000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 7.2630 - acc: 0.0000e+00 - auc: 0.0000e+00 - false_negatives: 978.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.2829 - acc: 0.0530 - auc: 0.0000e+00 - false_negatives: 268.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 15.0000 - precision: 1.0000 - recall: 0.0530\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.8109 - acc: 0.3279 - auc: 0.0000e+00 - false_negatives: 166.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 81.0000 - precision: 1.0000 - recall: 0.3279          \n",
            "42/42 [==============================] - 1s 18ms/step - loss: 7.5975e-04 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 4143.0000 - precision: 1.0000 - recall: 1.0000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.6150e-04 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 284.0000 - precision: 1.0000 - recall: 1.0000\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 7.4425e-04 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 3849.0000 - precision: 1.0000 - recall: 1.0000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0093 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 382.0000 - precision: 1.0000 - recall: 1.0000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6252 - acc: 0.8234 - auc: 0.0000e+00 - false_negatives: 98.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 457.0000 - precision: 1.0000 - recall: 0.8234\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0588 - acc: 0.9725 - auc: 0.0000e+00 - false_negatives: 19.0000 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 671.0000 - precision: 1.0000 - recall: 0.9725\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.1101e-04 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 7.0000 - precision: 1.0000 - recall: 1.0000\n",
            "217/217 [==============================] - 4s 17ms/step - loss: 0.0028 - acc: 1.0000 - auc: 0.0000e+00 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 0.0000e+00 - true_positives: 21615.0000 - precision: 1.0000 - recall: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cumulative distribution function"
      ],
      "metadata": {
        "id": "p-F4Eoh5H0cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "\n",
        "# normal distribution\n",
        "# sort the data in ascending order\n",
        "# get the cdf values of y\n",
        "# No of data points used\n",
        "N = len(users_acc)\n",
        "x = np.sort(users_acc)\n",
        "y = np.arange(N) / float(N)\n",
        "plt.plot(x, y,color='blue',label='Users')\n",
        "\n",
        "df=pd.DataFrame(columns=['x','y'])\n",
        "df['x']=x\n",
        "df['y']=y\n",
        "\n",
        "df.to_csv(\"/content/drive/My Drive/D/NEW 30-4-2022/CDF/users_cdf_200.csv\")\n",
        "\n",
        "\n",
        "N = len(trolls_acc)\n",
        "x = np.sort(trolls_acc)\n",
        "y = np.arange(N) / float(N)\n",
        "\n",
        "\n",
        "df=pd.DataFrame(columns=['x','y'])\n",
        "df['x']=x\n",
        "df['y']=y\n",
        "\n",
        "df.to_csv(\"/content/drive/My Drive/D/NEW 30-4-2022/CDF/trolls_cdf_200.csv\")\n",
        "plt.plot(x, y,color='red',label='Trolls')\n",
        "\n",
        "font = {'family' : 'normal',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 12}\n",
        "\n",
        "mpl.rc('font', **font)\n",
        "  \n",
        "# plotting\n",
        "plt.xlabel('Trolls score')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "VlMyzaRs08ST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "0db396dd-151a-466c-a6b1-8750ef47a612"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f04a67dfc90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydf = pd.DataFrame(columns=['score', 'label'])\n",
        "\n",
        "co = 0\n",
        "for i in range(len(trolls_acc)):\n",
        "  mydf.loc[co] = [trolls_acc[i], 1]\n",
        "  co = co + 1\n",
        "\n",
        "for i in range(len(users_acc)):\n",
        "  mydf.loc[co] = [users_acc[i],0]\n",
        "  co = co + 1\n",
        "\n",
        "mydf.to_csv(\"scores.csv\")"
      ],
      "metadata": {
        "id": "0BlsxisHsMtU"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Sy9xLUgwZiMa",
        "R8Eix89JZnzM",
        "8qGxXwm2ZL_Z",
        "Ap2AOnT5aEIj"
      ],
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}